{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for scientific research\n",
    "# Working with files and filesystems (file IO)\n",
    "# Answers to exercises\n",
    "\n",
    "### Bram Kuijper\n",
    "### University of Exeter, Penryn Campus, UK\n",
    "### February 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Go to the [``os.path``](https://docs.python.org/3/library/os.path.html#module-os.path) page and read through the various methods available. \n",
    "\n",
    "### Exercise 1.1\n",
    "Find the three functions you think are most often used to obtain information about a file or directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a matter of taste of what you deem important, but I would say:\n",
    "\n",
    "1. ``os.path.expanduser(path)``: when provided with ``path=\"~\"`` returns one's home directory as a ``str`` object.\n",
    "2. ``os.path.exists(path)``: when a file or directory given by ``path`` exists, returns ``True`` and ``False`` otherwise\n",
    "3. ``os.path.join(path1, path2, path3, ...etc)``: saefely multiple paths together. Concatenating strings (``path1 + \"/\" + path2``) can lead to errors, as you don't know whether ``\"\\\"`` (windows) or ``\"/\"`` (unix) is used as a path separator, or whether ``path1`` already has a trailing ``\"/\"`` as in ``\"/home/foo/bar/\"``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "The [``__file__``](https://docs.python.org/3/reference/import.html?highlight=__file__#__file__) variable contains the filename of the current python script. Write a function that is called ``current_file_info()``, accepts a file name as argument and returns a dictionary containing:\n",
    "  * the directory name in which your script resides\n",
    "  * the basename (i.e., ``script.py`` without the top-level directory)\n",
    "  * the extension of the script (if it is ``script.py`` it should give ``.py``)\n",
    "  * the creation time of the file (in seconds since January 1, 1970, 00:00:00 -- this sounds more difficult than it actually is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "\n",
    "def current_file_info(the_file):\n",
    "    \n",
    "    # get the absolute, not the relative path\n",
    "    the_file = os.path.abspath(the_file)\n",
    "    \n",
    "    # directory name\n",
    "    dirname = os.path.dirname(the_file)\n",
    "    \n",
    "    # the filename itself\n",
    "    basename = os.path.basename(the_file)\n",
    "    \n",
    "    # the extension\n",
    "    ext = os.path.splitext(the_file)[1]\n",
    "    \n",
    "    # the creation time\n",
    "    ctime = os.path.getctime(the_file)\n",
    "    \n",
    "    return({\"dir\":dirname,\"base\":basename,\"ext\":ext,\"ctime\":ctime})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your script, you can use the ``__file__`` variable. However, as I made these exercises in a notebook rather than a conventional Python script, this variable is not available. To this end, I just mimick this ``__file__`` by joining the current path (``\".\"``) with some random file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dir': '/home/bram/Projects/4_Teaching/2019_2020/Python/slides/day_2', 'base': 'some_script3834872492.py', 'ext': '.py', 'ctime': 1583232057.5712059}\n"
     ]
    }
   ],
   "source": [
    "# as the __file__ variable is not available within these\n",
    "# notebooks (only within scripts), we quickly create a temporary file\n",
    "__file_mimick = os.path.join(\n",
    "    os.path.abspath(\".\"),\"some_script3834872492.py\")\n",
    "\n",
    "with open(__file_mimick,mode=\"w\") as f:\n",
    "    f.write(\"some contents\")\n",
    "    \n",
    "print(current_file_info(the_file = __file_mimick))\n",
    "\n",
    "os.remove(__file_mimick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Getting raw text files into an object that is amenable for data analysis can sometimes be a tedious task. For most comma separated files, the function [``pandas.read_csv()``](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv) from the [pandas](https://pandas.pydata.org/) library does the job. However, in many other cases, the raw data contains descriptions, whitespace, irregular columns and other nuisances which means some preprocessing is necessary. Here we focus on such a case:\n",
    "\n",
    "### Exercise 2.1\n",
    "Inspect the [iso_8859-1.txt](https://www.w3.org/TR/PNG/iso_8859-1.txt) file by clicking on this [link](https://www.w3.org/TR/PNG/iso_8859-1.txt). Save the file somewhere on your home directory. If the file opens in another browser tab/window, press ctrl + s to save it to disk. The file contains the hexadecimal character code for the character set ISO-8859-1, but that is not important here. What we want to do is get **all the hexadecimal numbers in a single column, followed by their descriptions**. At the moment, however, there are sometimes one, sometimes two columns, and the whole thing is preceded by column names and a description, which need to be removed.\n",
    "\n",
    "### Exercise 2.2\n",
    "To start, write a function ``filter_hex_codes(pathname)`` that opens the file and only returns a list of lines containing either one or two hex codes and their descriptions. The description at the start of the file, or any whitespace at the start or end of each line (not in the middle) should have been removed. Hence, the first element of the list returned by this function should be ``['20  SPACE']``. The second element should be ``['21  EXCLAMATION MARK     A1  INVERTED EXCLAMATION MARK']`` and the last element should be ``['FF  SMALL LETTER Y WITH DIAERESIS']``. \n",
    "\n",
    "Hint: do not try to cram every possible pattern in a regex (although they will be needed). Look at other [text processing functions](https://docs.python.org/3/library/stdtypes.html?highlight=str%20split#string-methods) with which you can reduce the complexity of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20  SPACE',\n",
       " '21  EXCLAMATION MARK            A1  INVERTED EXCLAMATION MARK',\n",
       " '22  QUOTATION MARK              A2  CENT SIGN',\n",
       " '23  NUMBER SIGN                 A3  POUND SIGN',\n",
       " '24  DOLLAR SIGN                 A4  CURRENCY SIGN',\n",
       " '25  PERCENT SIGN                A5  YEN SIGN',\n",
       " '26  AMPERSAND                   A6  BROKEN BAR',\n",
       " '27  APOSTROPHE                  A7  SECTION SIGN',\n",
       " '28  LEFT PARENTHESIS            A8  DIAERESIS',\n",
       " '29  RIGHT PARENTHESIS           A9  COPYRIGHT SIGN',\n",
       " '2A  ASTERISK                    AA  FEMININE ORDINAL INDICATOR',\n",
       " '2B  PLUS SIGN                   AB  LEFT-POINTING DOUBLE ANGLE QUOTATION MARK',\n",
       " '2C  COMMA                       AC  NOT SIGN',\n",
       " '2D  HYPHEN-MINUS                AD  SOFT HYPHEN',\n",
       " '2E  FULL STOP                   AE  REGISTERED SIGN',\n",
       " '2F  SOLIDUS                     AF  OVERLINE',\n",
       " '30  DIGIT ZERO                  B0  DEGREE SIGN',\n",
       " '31  DIGIT ONE                   B1  PLUS-MINUS SIGN',\n",
       " '32  DIGIT TWO                   B2  SUPERSCRIPT TWO',\n",
       " '33  DIGIT THREE                 B3  SUPERSCRIPT THREE',\n",
       " '34  DIGIT FOUR                  B4  ACUTE ACCENT',\n",
       " '35  DIGIT FIVE                  B5  MICRO SIGN',\n",
       " '36  DIGIT SIX                   B6  PILCROW SIGN',\n",
       " '37  DIGIT SEVEN                 B7  MIDDLE DOT',\n",
       " '38  DIGIT EIGHT                 B8  CEDILLA',\n",
       " '39  DIGIT NINE                  B9  SUPERSCRIPT ONE',\n",
       " '3A  COLON                       BA  MASCULINE ORDINAL INDICATOR',\n",
       " '3B  SEMICOLON                   BB  RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK',\n",
       " '3C  LESS-THAN SIGN              BC  VULGAR FRACTION ONE QUARTER',\n",
       " '3D  EQUALS SIGN                 BD  VULGAR FRACTION ONE HALF',\n",
       " '3E  GREATER-THAN SIGN           BE  VULGAR FRACTION THREE QUARTERS',\n",
       " '3F  QUESTION MARK               BF  INVERTED QUESTION MARK',\n",
       " '40  COMMERCIAL AT               C0  CAPITAL LETTER A WITH GRAVE',\n",
       " '41  CAPITAL LETTER A            C1  CAPITAL LETTER A WITH ACUTE',\n",
       " '42  CAPITAL LETTER B            C2  CAPITAL LETTER A WITH CIRCUMFLEX',\n",
       " '43  CAPITAL LETTER C            C3  CAPITAL LETTER A WITH TILDE',\n",
       " '44  CAPITAL LETTER D            C4  CAPITAL LETTER A WITH DIAERESIS',\n",
       " '45  CAPITAL LETTER E            C5  CAPITAL LETTER A WITH RING ABOVE',\n",
       " '46  CAPITAL LETTER F            C6  CAPITAL LETTER AE',\n",
       " '47  CAPITAL LETTER G            C7  CAPITAL LETTER C WITH CEDILLA',\n",
       " '48  CAPITAL LETTER H            C8  CAPITAL LETTER E WITH GRAVE',\n",
       " '49  CAPITAL LETTER I            C9  CAPITAL LETTER E WITH ACUTE',\n",
       " '4A  CAPITAL LETTER J            CA  CAPITAL LETTER E WITH CIRCUMFLEX',\n",
       " '4B  CAPITAL LETTER K            CB  CAPITAL LETTER E WITH DIAERESIS',\n",
       " '4C  CAPITAL LETTER L            CC  CAPITAL LETTER I WITH GRAVE',\n",
       " '4D  CAPITAL LETTER M            CD  CAPITAL LETTER I WITH ACUTE',\n",
       " '4E  CAPITAL LETTER N            CE  CAPITAL LETTER I WITH CIRCUMFLEX',\n",
       " '4F  CAPITAL LETTER O            CF  CAPITAL LETTER I WITH DIAERESIS',\n",
       " '50  CAPITAL LETTER P            D0  CAPITAL LETTER ETH (Icelandic)',\n",
       " '51  CAPITAL LETTER Q            D1  CAPITAL LETTER N WITH TILDE',\n",
       " '52  CAPITAL LETTER R            D2  CAPITAL LETTER O WITH GRAVE',\n",
       " '53  CAPITAL LETTER S            D3  CAPITAL LETTER O WITH ACUTE',\n",
       " '54  CAPITAL LETTER T            D4  CAPITAL LETTER O WITH CIRCUMFLEX',\n",
       " '55  CAPITAL LETTER U            D5  CAPITAL LETTER O WITH TILDE',\n",
       " '56  CAPITAL LETTER V            D6  CAPITAL LETTER O WITH DIAERESIS',\n",
       " '57  CAPITAL LETTER W            D7  MULTIPLICATION SIGN',\n",
       " '58  CAPITAL LETTER X            D8  CAPITAL LETTER O WITH STROKE',\n",
       " '59  CAPITAL LETTER Y            D9  CAPITAL LETTER U WITH GRAVE',\n",
       " '5A  CAPITAL LETTER Z            DA  CAPITAL LETTER U WITH ACUTE',\n",
       " '5B  LEFT SQUARE BRACKET         DB  CAPITAL LETTER U WITH CIRCUMFLEX',\n",
       " '5C  REVERSE SOLIDUS             DC  CAPITAL LETTER U WITH DIAERESIS',\n",
       " '5D  RIGHT SQUARE BRACKET        DD  CAPITAL LETTER Y WITH ACUTE',\n",
       " '5E  CIRCUMFLEX ACCENT           DE  CAPITAL LETTER THORN (Icelandic)',\n",
       " '5F  LOW LINE                    DF  SMALL LETTER SHARP S (German)',\n",
       " '60  GRAVE ACCENT                E0  SMALL LETTER A WITH GRAVE',\n",
       " '61  SMALL LETTER A              E1  SMALL LETTER A WITH ACUTE',\n",
       " '62  SMALL LETTER B              E2  SMALL LETTER A WITH CIRCUMFLEX',\n",
       " '63  SMALL LETTER C              E3  SMALL LETTER A WITH TILDE',\n",
       " '64  SMALL LETTER D              E4  SMALL LETTER A WITH DIAERESIS',\n",
       " '65  SMALL LETTER E              E5  SMALL LETTER A WITH RING ABOVE',\n",
       " '66  SMALL LETTER F              E6  SMALL LETTER AE',\n",
       " '67  SMALL LETTER G              E7  SMALL LETTER C WITH CEDILLA',\n",
       " '68  SMALL LETTER H              E8  SMALL LETTER E WITH GRAVE',\n",
       " '69  SMALL LETTER I              E9  SMALL LETTER E WITH ACUTE',\n",
       " '6A  SMALL LETTER J              EA  SMALL LETTER E WITH CIRCUMFLEX',\n",
       " '6B  SMALL LETTER K              EB  SMALL LETTER E WITH DIAERESIS',\n",
       " '6C  SMALL LETTER L              EC  SMALL LETTER I WITH GRAVE',\n",
       " '6D  SMALL LETTER M              ED  SMALL LETTER I WITH ACUTE',\n",
       " '6E  SMALL LETTER N              EE  SMALL LETTER I WITH CIRCUMFLEX',\n",
       " '6F  SMALL LETTER O              EF  SMALL LETTER I WITH DIAERESIS',\n",
       " '70  SMALL LETTER P              F0  SMALL LETTER ETH (Icelandic)',\n",
       " '71  SMALL LETTER Q              F1  SMALL LETTER N WITH TILDE',\n",
       " '72  SMALL LETTER R              F2  SMALL LETTER O WITH GRAVE',\n",
       " '73  SMALL LETTER S              F3  SMALL LETTER O WITH ACUTE',\n",
       " '74  SMALL LETTER T              F4  SMALL LETTER O WITH CIRCUMFLEX',\n",
       " '75  SMALL LETTER U              F5  SMALL LETTER O WITH TILDE',\n",
       " '76  SMALL LETTER V              F6  SMALL LETTER O WITH DIAERESIS',\n",
       " '77  SMALL LETTER W              F7  DIVISION SIGN',\n",
       " '78  SMALL LETTER X              F8  SMALL LETTER O WITH STROKE',\n",
       " '79  SMALL LETTER Y              F9  SMALL LETTER U WITH GRAVE',\n",
       " '7A  SMALL LETTER Z              FA  SMALL LETTER U WITH ACUTE',\n",
       " '7B  LEFT CURLY BRACKET          FB  SMALL LETTER U WITH CIRCUMFLEX',\n",
       " '7C  VERTICAL LINE               FC  SMALL LETTER U WITH DIAERESIS',\n",
       " '7D  RIGHT CURLY BRACKET         FD  SMALL LETTER Y WITH ACUTE',\n",
       " '7E  TILDE                       FE  SMALL LETTER THORN (Icelandic)',\n",
       " 'FF  SMALL LETTER Y WITH DIAERESIS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def filter_hex_codes(filename):\n",
    "    \n",
    "    filtered_list = []\n",
    "       \n",
    "    with open(file=filename, mode=\"r\") as f_obj:\n",
    "\n",
    "        for line in f_obj:\n",
    "            \n",
    "            # strip whitespace\n",
    "            # this immediately removes hassle with the last line\n",
    "            # as that is now 'FF  SMALL LETTER Y WITH DIAERESIS'\n",
    "            stripped_line = line.strip()\n",
    "            \n",
    "            # match a line starting a hexadecimal character\n",
    "            if re.search(pattern=\"^[0-9A-F]\", string=stripped_line) != None:\n",
    "                filtered_list.append(stripped_line)\n",
    "                \n",
    "    return(filtered_list)\n",
    "                    \n",
    "file_name = \"iso_8859-1.txt\"\n",
    "hex_list = filter_hex_codes(filename=file_name)\n",
    "\n",
    "# output in notebook:\n",
    "[i for i in hex_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3\n",
    "Make another function that accepts the list returned by ``filter_hex_codes(pathname)`` and prints the two columns of  \n",
    "``hex code  character description      hex code  character description``   \n",
    "as a single ``;``-separated list of  \n",
    "``hex code;character description ``  \n",
    "\n",
    "The order of the hex code in the list is not important.\n",
    "\n",
    "A potential output could be:\n",
    "\n",
    "``['20;SPACE',\n",
    " '21;EXCLAMATION MARK',\n",
    " 'A1;INVERTED EXCLAMATION MARK',\n",
    " '22;QUOTATION MARK',\n",
    " 'A2;CENT SIGN',\n",
    " '23;NUMBER SIGN',\n",
    " 'A3;POUND SIGN',\n",
    " ...\n",
    " '7E;TILDE',\n",
    " 'FE;SMALL LETTER THORN (Icelandic)',\n",
    " 'FF;SMALL LETTER Y WITH DIAERESIS']``\n",
    "\n",
    "**Hint:** check out ``re.split()`` if you want to split a line based on a slightly more complicated pattern than possible with ``str.split()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20;SPACE',\n",
       " '21;EXCLAMATION MARK',\n",
       " 'A1;INVERTED EXCLAMATION MARK',\n",
       " '22;QUOTATION MARK',\n",
       " 'A2;CENT SIGN',\n",
       " '23;NUMBER SIGN',\n",
       " 'A3;POUND SIGN',\n",
       " '24;DOLLAR SIGN',\n",
       " 'A4;CURRENCY SIGN',\n",
       " '25;PERCENT SIGN',\n",
       " 'A5;YEN SIGN',\n",
       " '26;AMPERSAND',\n",
       " 'A6;BROKEN BAR',\n",
       " '27;APOSTROPHE',\n",
       " 'A7;SECTION SIGN',\n",
       " '28;LEFT PARENTHESIS',\n",
       " 'A8;DIAERESIS',\n",
       " '29;RIGHT PARENTHESIS',\n",
       " 'A9;COPYRIGHT SIGN',\n",
       " '2A;ASTERISK',\n",
       " 'AA;FEMININE ORDINAL INDICATOR',\n",
       " '2B;PLUS SIGN',\n",
       " 'AB;LEFT-POINTING DOUBLE ANGLE QUOTATION MARK',\n",
       " '2C;COMMA',\n",
       " 'AC;NOT SIGN',\n",
       " '2D;HYPHEN-MINUS',\n",
       " 'AD;SOFT HYPHEN',\n",
       " '2E;FULL STOP',\n",
       " 'AE;REGISTERED SIGN',\n",
       " '2F;SOLIDUS',\n",
       " 'AF;OVERLINE',\n",
       " '30;DIGIT ZERO',\n",
       " 'B0;DEGREE SIGN',\n",
       " '31;DIGIT ONE',\n",
       " 'B1;PLUS-MINUS SIGN',\n",
       " '32;DIGIT TWO',\n",
       " 'B2;SUPERSCRIPT TWO',\n",
       " '33;DIGIT THREE',\n",
       " 'B3;SUPERSCRIPT THREE',\n",
       " '34;DIGIT FOUR',\n",
       " 'B4;ACUTE ACCENT',\n",
       " '35;DIGIT FIVE',\n",
       " 'B5;MICRO SIGN',\n",
       " '36;DIGIT SIX',\n",
       " 'B6;PILCROW SIGN',\n",
       " '37;DIGIT SEVEN',\n",
       " 'B7;MIDDLE DOT',\n",
       " '38;DIGIT EIGHT',\n",
       " 'B8;CEDILLA',\n",
       " '39;DIGIT NINE',\n",
       " 'B9;SUPERSCRIPT ONE',\n",
       " '3A;COLON',\n",
       " 'BA;MASCULINE ORDINAL INDICATOR',\n",
       " '3B;SEMICOLON',\n",
       " 'BB;RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK',\n",
       " '3C;LESS-THAN SIGN',\n",
       " 'BC;VULGAR FRACTION ONE QUARTER',\n",
       " '3D;EQUALS SIGN',\n",
       " 'BD;VULGAR FRACTION ONE HALF',\n",
       " '3E;GREATER-THAN SIGN',\n",
       " 'BE;VULGAR FRACTION THREE QUARTERS',\n",
       " '3F;QUESTION MARK',\n",
       " 'BF;INVERTED QUESTION MARK',\n",
       " '40;COMMERCIAL AT',\n",
       " 'C0;CAPITAL LETTER A WITH GRAVE',\n",
       " '41;CAPITAL LETTER A',\n",
       " 'C1;CAPITAL LETTER A WITH ACUTE',\n",
       " '42;CAPITAL LETTER B',\n",
       " 'C2;CAPITAL LETTER A WITH CIRCUMFLEX',\n",
       " '43;CAPITAL LETTER C',\n",
       " 'C3;CAPITAL LETTER A WITH TILDE',\n",
       " '44;CAPITAL LETTER D',\n",
       " 'C4;CAPITAL LETTER A WITH DIAERESIS',\n",
       " '45;CAPITAL LETTER E',\n",
       " 'C5;CAPITAL LETTER A WITH RING ABOVE',\n",
       " '46;CAPITAL LETTER F',\n",
       " 'C6;CAPITAL LETTER AE',\n",
       " '47;CAPITAL LETTER G',\n",
       " 'C7;CAPITAL LETTER C WITH CEDILLA',\n",
       " '48;CAPITAL LETTER H',\n",
       " 'C8;CAPITAL LETTER E WITH GRAVE',\n",
       " '49;CAPITAL LETTER I',\n",
       " 'C9;CAPITAL LETTER E WITH ACUTE',\n",
       " '4A;CAPITAL LETTER J',\n",
       " 'CA;CAPITAL LETTER E WITH CIRCUMFLEX',\n",
       " '4B;CAPITAL LETTER K',\n",
       " 'CB;CAPITAL LETTER E WITH DIAERESIS',\n",
       " '4C;CAPITAL LETTER L',\n",
       " 'CC;CAPITAL LETTER I WITH GRAVE',\n",
       " '4D;CAPITAL LETTER M',\n",
       " 'CD;CAPITAL LETTER I WITH ACUTE',\n",
       " '4E;CAPITAL LETTER N',\n",
       " 'CE;CAPITAL LETTER I WITH CIRCUMFLEX',\n",
       " '4F;CAPITAL LETTER O',\n",
       " 'CF;CAPITAL LETTER I WITH DIAERESIS',\n",
       " '50;CAPITAL LETTER P',\n",
       " 'D0;CAPITAL LETTER ETH (Icelandic)',\n",
       " '51;CAPITAL LETTER Q',\n",
       " 'D1;CAPITAL LETTER N WITH TILDE',\n",
       " '52;CAPITAL LETTER R',\n",
       " 'D2;CAPITAL LETTER O WITH GRAVE',\n",
       " '53;CAPITAL LETTER S',\n",
       " 'D3;CAPITAL LETTER O WITH ACUTE',\n",
       " '54;CAPITAL LETTER T',\n",
       " 'D4;CAPITAL LETTER O WITH CIRCUMFLEX',\n",
       " '55;CAPITAL LETTER U',\n",
       " 'D5;CAPITAL LETTER O WITH TILDE',\n",
       " '56;CAPITAL LETTER V',\n",
       " 'D6;CAPITAL LETTER O WITH DIAERESIS',\n",
       " '57;CAPITAL LETTER W',\n",
       " 'D7;MULTIPLICATION SIGN',\n",
       " '58;CAPITAL LETTER X',\n",
       " 'D8;CAPITAL LETTER O WITH STROKE',\n",
       " '59;CAPITAL LETTER Y',\n",
       " 'D9;CAPITAL LETTER U WITH GRAVE',\n",
       " '5A;CAPITAL LETTER Z',\n",
       " 'DA;CAPITAL LETTER U WITH ACUTE',\n",
       " '5B;LEFT SQUARE BRACKET',\n",
       " 'DB;CAPITAL LETTER U WITH CIRCUMFLEX',\n",
       " '5C;REVERSE SOLIDUS',\n",
       " 'DC;CAPITAL LETTER U WITH DIAERESIS',\n",
       " '5D;RIGHT SQUARE BRACKET',\n",
       " 'DD;CAPITAL LETTER Y WITH ACUTE',\n",
       " '5E;CIRCUMFLEX ACCENT',\n",
       " 'DE;CAPITAL LETTER THORN (Icelandic)',\n",
       " '5F;LOW LINE',\n",
       " 'DF;SMALL LETTER SHARP S (German)',\n",
       " '60;GRAVE ACCENT',\n",
       " 'E0;SMALL LETTER A WITH GRAVE',\n",
       " '61;SMALL LETTER A',\n",
       " 'E1;SMALL LETTER A WITH ACUTE',\n",
       " '62;SMALL LETTER B',\n",
       " 'E2;SMALL LETTER A WITH CIRCUMFLEX',\n",
       " '63;SMALL LETTER C',\n",
       " 'E3;SMALL LETTER A WITH TILDE',\n",
       " '64;SMALL LETTER D',\n",
       " 'E4;SMALL LETTER A WITH DIAERESIS',\n",
       " '65;SMALL LETTER E',\n",
       " 'E5;SMALL LETTER A WITH RING ABOVE',\n",
       " '66;SMALL LETTER F',\n",
       " 'E6;SMALL LETTER AE',\n",
       " '67;SMALL LETTER G',\n",
       " 'E7;SMALL LETTER C WITH CEDILLA',\n",
       " '68;SMALL LETTER H',\n",
       " 'E8;SMALL LETTER E WITH GRAVE',\n",
       " '69;SMALL LETTER I',\n",
       " 'E9;SMALL LETTER E WITH ACUTE',\n",
       " '6A;SMALL LETTER J',\n",
       " 'EA;SMALL LETTER E WITH CIRCUMFLEX',\n",
       " '6B;SMALL LETTER K',\n",
       " 'EB;SMALL LETTER E WITH DIAERESIS',\n",
       " '6C;SMALL LETTER L',\n",
       " 'EC;SMALL LETTER I WITH GRAVE',\n",
       " '6D;SMALL LETTER M',\n",
       " 'ED;SMALL LETTER I WITH ACUTE',\n",
       " '6E;SMALL LETTER N',\n",
       " 'EE;SMALL LETTER I WITH CIRCUMFLEX',\n",
       " '6F;SMALL LETTER O',\n",
       " 'EF;SMALL LETTER I WITH DIAERESIS',\n",
       " '70;SMALL LETTER P',\n",
       " 'F0;SMALL LETTER ETH (Icelandic)',\n",
       " '71;SMALL LETTER Q',\n",
       " 'F1;SMALL LETTER N WITH TILDE',\n",
       " '72;SMALL LETTER R',\n",
       " 'F2;SMALL LETTER O WITH GRAVE',\n",
       " '73;SMALL LETTER S',\n",
       " 'F3;SMALL LETTER O WITH ACUTE',\n",
       " '74;SMALL LETTER T',\n",
       " 'F4;SMALL LETTER O WITH CIRCUMFLEX',\n",
       " '75;SMALL LETTER U',\n",
       " 'F5;SMALL LETTER O WITH TILDE',\n",
       " '76;SMALL LETTER V',\n",
       " 'F6;SMALL LETTER O WITH DIAERESIS',\n",
       " '77;SMALL LETTER W',\n",
       " 'F7;DIVISION SIGN',\n",
       " '78;SMALL LETTER X',\n",
       " 'F8;SMALL LETTER O WITH STROKE',\n",
       " '79;SMALL LETTER Y',\n",
       " 'F9;SMALL LETTER U WITH GRAVE',\n",
       " '7A;SMALL LETTER Z',\n",
       " 'FA;SMALL LETTER U WITH ACUTE',\n",
       " '7B;LEFT CURLY BRACKET',\n",
       " 'FB;SMALL LETTER U WITH CIRCUMFLEX',\n",
       " '7C;VERTICAL LINE',\n",
       " 'FC;SMALL LETTER U WITH DIAERESIS',\n",
       " '7D;RIGHT CURLY BRACKET',\n",
       " 'FD;SMALL LETTER Y WITH ACUTE',\n",
       " '7E;TILDE',\n",
       " 'FE;SMALL LETTER THORN (Icelandic)',\n",
       " 'FF;SMALL LETTER Y WITH DIAERESIS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_column_list_unordered(multicolumn_list):\n",
    "    \n",
    "    # make a new list for the new elements which \n",
    "    # reflect a single column only\n",
    "    single_col_list = []\n",
    "    \n",
    "    # go through each line\n",
    "    for list_elmt in multicolumn_list:\n",
    "        \n",
    "        # split the list according to the occurrence of 2 or more whitespaces\n",
    "        # one whitespace is not enough as you then also split your descriptions (a mess...)\n",
    "        split_list = re.split(pattern=r\"\\s{2,}\",string=list_elmt)\n",
    "        \n",
    "        # always at least a single hit\n",
    "        single_col_list.append(split_list[0:2])\n",
    "           \n",
    "        # but potentially another hit too\n",
    "        if len(split_list) == 4:\n",
    "            single_col_list.append(split_list[2:4])\n",
    "       \n",
    "    # add semicolons using a list comprehension\n",
    "    csv_list = [\";\".join(i) for i in single_col_list]\n",
    "    return(csv_list)\n",
    "        \n",
    "# call the function\n",
    "result_list = single_column_list_unordered(multicolumn_list=hex_list)\n",
    "\n",
    "[i for i in result_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4\n",
    "Write the contents to a file ``iso_8859-1-single-columnn.txt``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join string together in a list\n",
    "single_str = \"\\n\".join(result_list)\n",
    "\n",
    "with open(file=\"iso_8859-1-single-columnn.txt\",mode=\"w\") as f_obj:\n",
    "    f_obj.write(single_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Bringing data together from multiple files is another task for which Python is commonly used. Here we work on a directory containing a range of different files and try to combine data\n",
    "\n",
    "### Exercise 3.1\n",
    "Download and unpack the zip file in the following [link](https://github.com/bramkuijper/stress/raw/master/figs/compare_dp/some_data.zip). Move it to a folder somewhere in your home directory (we are not going to delete anything so no worries) and inspect the directory structure. It contains different files distributed over a bunch of subdirectories. Using notepad to open a file may be less than helpful, but one can always use the menu option ``File``>``Open`` in Spyder to inspect a raw data file. Just make sure that the `All files` option is selected in the `Select file` dialog.\n",
    "\n",
    "### Exercise 3.2\n",
    "Write a function ``files_matching_regex(pattern, path)`` which uses the [``os.walk()``](https://docs.python.org/3/library/os.html#os.walk) function to loop over all files in the unpacked zip file above. It returns a list with the complete pathnames of those files which match to a certain regular expression given by ``pattern``. The location of the top-level directory containing the data should be provided by the keyword argument ``path``.\n",
    "\n",
    "Then test the function and (i) specify a pattern which matches all the files ending on `.csv` and (ii) another pattern that matches all the files containing `02_2020` but are neither preceded by `graph` nor end on `*_iters.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_matching_regex(pattern, path):\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "    \n",
    "    matching_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(top=path):\n",
    "        \n",
    "        # files is a list of files in the current directory\n",
    "        for file in files:\n",
    "            if re.search(pattern=pattern, string=file) != None:\n",
    "                matching_files.append(os.path.join(root,file))\n",
    "                \n",
    "    return(matching_files)\n",
    "\n",
    "the_path = \"/home/bram/Projects/stress/figs/compare_dp/some_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bram/Projects/stress/figs/compare_dp/some_data/dir5/sim_stress_17_02_2020_152706_3iters.csv',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir4/sim_stress_17_02_2020_152706_5iters.csv',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir3/sim_stress_17_02_2020_152706_4iters.csv',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir3/dir3a/sim_stress_14_02_2020_232531_3iters.csv',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir1/sim_stress_17_02_2020_152706_2iters.csv',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir2/sim_stress_17_02_2020_152622_1iters.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the regex\n",
    "csv_pattern = \"csv$\"\n",
    "\n",
    "# call the function and return a list\n",
    "csv_matches = files_matching_regex(pattern=csv_pattern, path=the_path)\n",
    "\n",
    "# just for output purposes:\n",
    "[match_i for match_i in csv_matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching files containing `02_2020` but are neither preceded by `graph` nor end on `*_iters.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bram/Projects/stress/figs/compare_dp/some_data/sim_stress_17_02_2020_182706_4',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir5/sim_stress_17_02_2020_152706_3',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir4/sim_stress_17_02_2020_152706_5',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir3/sim_stress_17_02_2020_152706_4',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir3/dir3a/sim_stress_14_02_2020_232531_3',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir1/sim_stress_17_02_2020_152706_2',\n",
       " '/home/bram/Projects/stress/figs/compare_dp/some_data/dir2/sim_stress_17_02_2020_152622_1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feb2020_pattern = \"^sim.*02_2020.*\\d$\"\n",
    "\n",
    "feb2020_matches = files_matching_regex(pattern=feb2020_pattern, path=the_path)\n",
    "\n",
    "[match_i for match_i in feb2020_matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "Now write another function ``match_line(path, pattern)`` that opens a file given by keyword argument ``path`` and which returns the first line matching the keyword argument ``pattern``. Now use this function in combination with the ``files_matching_regex(pattern, path)`` function above to get a list of all the lines starting with `sP2NP` from all files starting with `sim` and ending on the digits `1`, `3` and `5`. The listing should be (not necessarily in this order):\n",
    "\n",
    "``['sP2NP_1;0.19;', 'sP2NP_1;0.19;', 'sP2NP_1;0.5;', 'sP2NP_1;0.89;']``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_line(path, pattern):\n",
    "    \n",
    "    with open(path) as f_obj:\n",
    "        \n",
    "        for line in f_obj:\n",
    "            if re.search(pattern=pattern, string=line) != None:\n",
    "                return(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bram/Projects/stress/figs/compare_dp/some_data/dir5/sim_stress_17_02_2020_152706_3\n",
      "/home/bram/Projects/stress/figs/compare_dp/some_data/dir4/sim_stress_17_02_2020_152706_5\n",
      "/home/bram/Projects/stress/figs/compare_dp/some_data/dir3/dir3a/sim_stress_14_02_2020_232531_3\n",
      "/home/bram/Projects/stress/figs/compare_dp/some_data/dir2/sim_stress_17_02_2020_152622_1\n",
      "['sP2NP_1;0.19;', 'sP2NP_1;0.5;', 'sP2NP_1;0.89;', 'sP2NP_1;0.19;']\n"
     ]
    }
   ],
   "source": [
    "sim_last_digit_pattern = \"^sim.*[135]$\"\n",
    "\n",
    "matches =  files_matching_regex(pattern=sim_last_digit_pattern, path=the_path)\n",
    "\n",
    "# print all the matching files\n",
    "print(\"\\n\".join(matches))\n",
    "\n",
    "# now recover the matching lines\n",
    "param_list = [match_line(path=path_i,pattern=\"sP2NP\") for path_i in matches]\n",
    "\n",
    "print(param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
